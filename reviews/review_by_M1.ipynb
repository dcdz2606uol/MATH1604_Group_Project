{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cd52d6-7924-4f47-a092-33b2c9769a83",
   "metadata": {},
   "source": [
    "# Reviewer: Abraham Sobowale #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba01be4c-75da-402e-aefe-41a83bfcc730",
   "metadata": {},
   "source": [
    "# M1: Parsing Module  #\n",
    "## Objective of `data_extraction_M1.py`\n",
    "The module provides two core functions for handling quiz answer data:\n",
    "* `extract_answers_sequence()`: Parses raw quiz files into structured answer sequences\n",
    "* `write_answers_sequence()`: Writes processed sequences to respondent-specific files\n",
    "\n",
    "## Key Functions Review\n",
    "* #### `extract_answers_sequence()`: Parse a quiz answers text file into a list of 100 integers. Then maps each answer to (1, 2, 3, 4) or 0 if unanswered\n",
    "* > M1 Has code for file handling in the section where the try function helps prevent file-related errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4b81e-e61a-4af9-bf33-d0abc2733316",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c9b6f-5367-4601-9282-5b14207e768e",
   "metadata": {},
   "source": [
    "* > Error debugging code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21455b5-e4bb-4858-a53f-f1998be8e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found: {file_path}\")\n",
    "    return None\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\") \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a818d053-4af9-4de9-8a25-57e66af8e403",
   "metadata": {},
   "source": [
    "* > M1 scans each block for X or [ ] and breaks once the answer is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0df985-f8ed-4ced-87e5-4979ef945b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, block in enumerate(question_blocks[:100]):  # Process up to 100 questions\n",
    "    for line in block.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line.startswith('[x]'):  \n",
    "            answers[i] = option_number  # Store selected option (1-4)\n",
    "            break\n",
    "        elif line.startswith('[ ]'):  \n",
    "            option_number += 1  # Track option positon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c8f6c-ea95-4ffe-94b3-939e54444b94",
   "metadata": {},
   "source": [
    "* #### `write_answers_sequence()`: Take the extracted list of answers and ID nu\n",
    "* * > M1: has a section for file writing to overwrite/creates the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96b8e3-e823-4c38-bbaa-02739ee9dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answers_sequence(answer = list, n = int):\n",
    "    file_name = f\"answers_list_respondent_{n}.txt\" # Sets file name to n\n",
    "    f = open(file_name, \"w\") # Creates file if it's not there before\n",
    "    answer = str(answer) # Convert to string in order to write\n",
    "    f.write(answer)\n",
    "    f.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902dad2f-9db0-48a3-b7e0-3a5b2f1457ab",
   "metadata": {},
   "source": [
    "## Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e87f1-6d45-490a-b838-00af7e666112",
   "metadata": {},
   "source": [
    "### `extract_answers_sequence()`i* Error printing while useful can limit the integration usage in future projects\n",
    "* There's no validation code for the file's content so malformed files can produce error data (Example : The questions could be made incorrectly or randomised)\n",
    "* Hardcoded for 100 questions when it could be adjusted with another parameter (Example: 50 questions?)\n",
    "### `write_answers_sequence()`\n",
    "* the default parameters = list and =int are incorrect (Should be :int and :list)\n",
    "* There's no validation code for the file's content or the answer list length\n",
    "\n",
    "## Conclusion\n",
    "The parsing module does it's core functions effectively but would benefit from:\n",
    "* Better error handling\n",
    "* More flexible question handling\n",
    "* CORRECT Type hintst Summary\n",
    "When running the 1st function: in an text s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc5253d-e2ae-49b7-9224-d75ab2230a8e",
   "metadata": {},
   "source": [
    "# M2: Download & Collation Module  #\n",
    "\n",
    "## Objective of `data_preparation_M2.py`\n",
    "The module handles downloading and combining quiz answer files:\n",
    "* `download_answer_files()`: Recieves answer files from a cloud storage\n",
    "* `collate_answer_files()`: Combines individual files into a combined output\n",
    "\n",
    "## Key Functions Review\n",
    "* #### `download_answer_files()`: Downloads all the files from a cloud server and stores them.\n",
    "* > M2 Has code for file handling in the section where a folder will be made if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918605f-667e-461a-9ffc-6953a9418bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if not os.path.exists(save_folder):\n",
    "        os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de00ce-57bd-4cc7-a3d3-03cccb6a3dc6",
   "metadata": {},
   "source": [
    "* > Download ror debugging  and verification code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443466f-d4e2-46cc-a895-dc5547cb877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Saved: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {url}\")None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062da29d-738a-49d7-bebf-a98fe2aaba58",
   "metadata": {},
   "source": [
    "* > M2 downloads from cloud_url  and sets the destination folder to \"save_folder\" as \"file_name\" found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd65a0-0ef2-4f9b-9da7-8190b7543cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, total_files + 1):\n",
    "        url = f\"{cloud_url}/answers_respondent_{i}.txt\"\n",
    "        file_name = f\"answers_respondent_{i}.txt\"\n",
    "        file_path = os.path.join(save_folder, file_name)tion`collate_answer_files()`s_sequs nce(files and combines them into 1 files with all the content. a teM2 Has code for file handling in the section where a folder will be made if it doesn't existates     \n",
    "        if not os.path.exists(\"output\"):\n",
    "        os.mkdir(\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5da235-983d-4f2d-b183-5d50b3a83079",
   "metadata": {},
   "source": [
    "* > M2 creates a files where all the previous will be written into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ddd36-11ad-495c-af18-a0caade2ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Open the final file for writing\n",
    "    with open(\"output/collated_answers.txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "        # Find and sort all respondent files\n",
    "        files = [f for f in os.listdir(folder_path) if f.startswith(\"answers_respondent_\")]\n",
    "        files.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "\n",
    "        for i, file_name in enumerate(files):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read().strip()\n",
    "                out_file.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c50931d-3312-48d5-8c52-fe25613d921c",
   "metadata": {},
   "source": [
    "## Relfections\n",
    "\n",
    "### `download_answer_files()`\n",
    "* No way to retry to download any failed download(Ex. If a download fails from a temp network issue)\n",
    "* There's no verification code for the file's content so corrupted files can produce error data (Example : The questions could be made incorrectly or randomised)\n",
    "* No type hints (Ex: someone can input a real number)\n",
    "### `collate_answer_files()`\n",
    "* No validation for the folder's existence\n",
    "* There's no validation code for malformed files\n",
    "\n",
    "## Conclusion\n",
    "The parsing module does it's core functions effectively but would benefit from:\n",
    "* Better error handling for files\n",
    "* Better verfication methods for folders and files\n",
    "* Type hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57010c3e-2d4d-44f5-9f5f-33fd9670595a",
   "metadata": {},
   "source": [
    "# M3: Analysis Module #\n",
    "\n",
    "## Objective of `data_preparation_M2.py`\n",
    "The module handles downloading and combining quiz answer files:\n",
    "* `generate_means_sequence()`: Recieves answer files from a cloud storage\n",
    "* `visualize_data()`: Combines individual files into a combined output\n",
    "\n",
    "## Key Functions Review\n",
    "* #### `generate_means_sequence()`: Recieves the data from the collated file and calcuates the mean from it.\n",
    "* > M3 Has code for file reading in the section but there's no verification for its existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f010012-f9b3-4ddb-b27e-b8849da70d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(collated_answers_path, 'r', encoding='utf-8') as file:\n",
    "    raw_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1fe3c-d0e2-4edc-b1fa-f8635b301ad9",
   "metadata": {},
   "source": [
    "*  Extracting the sequences to write to a temp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14a250-0a49-4de5-8b37-7ec0b6931e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in respondent_blocks:\n",
    "    temp_path = 'temp_response.txt'\n",
    "    with open(temp_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(block.strip())\n",
    "    seq = extract_answers_sequence(temp_path)\n",
    "    os.remove(temp_path)\n",
    "    if seq and len(seq) == 100:\n",
    "        all_sequences.append(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0a201-9d10-4cf5-bfb3-68be673f408b",
   "metadata": {},
   "source": [
    "* > M3 Calculates the mean for each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474a531-ae18-4d88-8cb3-eaa286cec543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    values = [seq[i] for seq in all_sequences if seq[i] != 0]\n",
    "    mean = sum(values) / len(values) if values else 0.0\n",
    "    means.append(mean)\n",
    "return meansle_name)\n",
    "visualize_data_answer_files("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f50d5-356f-4cf4-b510-b37b03350548",
   "metadata": {},
   "source": [
    "* > Takes the files and combines them into 1 files with all the c3 Loads and parses the data into a structured sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e83d2-6979-465a-9442-e32d9759bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(collated_answers_path, 'r', encoding='utf-8') as file:\n",
    "    raw_data = file.read()\n",
    "\n",
    "respondent_blocks = raw_data.strip().split('\\n*\\n')\n",
    "all_sequences = []\n",
    "\n",
    "for block in respondent_blocks:\n",
    "    temp_path = 'temp_response.txt'\n",
    "    with open(temp_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(block.strip())\n",
    "    seq = extract_answers_sequence(temp_path)\n",
    "    os.remove(temp_path)\n",
    "    if seq and len(seq) == 100:\n",
    "        all_sequences.append(seq3 Generates the plots based off the user's inputus wiif n == 1:\n",
    "    means = generate_means_sequence(collated_answers_path)\n",
    "    plt.scatter(range(1, 101), means, color='blue')\n",
    "    plt.title('Mean Answer Value per Question (Scatter)')\n",
    "    plt.xlabel('Question Number')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "elif n == 2:\n",
    "    for seq in all_sequences:\n",
    "        plt.plot(range(1, 101), seq, alpha=0.4)\n",
    "    plt.title('Individual Respondent Answer Patterns (Line Plot)')\n",
    "    plt.xlabel('Question Number')\n",
    "    plt.ylabel('Answer Value')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Error: Invalid visualization type. Use 1 for scaer, 2\n",
    " for line.\")   out_filgenerate_means_sequence``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beda538-a627-40a8-ada1-3fd5178eef16",
   "metadata": {},
   "source": [
    "## Relfections\n",
    "\n",
    "### `download_answer_files()`\n",
    "* Temp file creation and deletion isn't the most efficent method(Ex. to prevent duplicated code and data)\n",
    "* No error hanlding for files\n",
    "* Duplicated code visualize_data in both functions)\n",
    "### `collate_answer_files()`\n",
    "* No figure size or \n",
    "* Too many plots in the line charts (Makes it hard to understand)\n",
    "\n",
    "## Conclusion\n",
    "This module does it's core functions effectively but would benefit from:\n",
    "* Modular coding\n",
    "* Add plot customizing options\n",
    "* Type hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b9d538-e673-4839-9340-3d0f62047bf3",
   "metadata": {},
   "source": [
    "# M4: Integration & Execution  #\n",
    "\n",
    "## Objective of `run_full_analysis_M4.py`\n",
    "The module handles downloading and combining quiz answer files:\n",
    "* `download_answer_files()`: Recieves answer files from a cloud storage\n",
    "* `collate_answer_files()`: Combines individual files into a combined output\n",
    "\n",
    "## Key Functions Review\n",
    "* #### `setup_environment()`: Sets-up directory and cleans the log files to allow for no permission issues and validate the filesystem permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a640a-430c-4f59-830e-afdcf1e44473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    os.makedirs(CONFIG['data_folder'], exist_ok=True)\n",
    "    os.makedirs(CONFIG['output_folder'], exist_ok=True)\n",
    "    with open(CONFIG['log_file'], 'w') as f:\n",
    "        f.write(f\"Analysis Log - {datetime.now()}\\n{'='*40}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51a1cd-aade-4a79-801c-6a3eb839a562",
   "metadata": {},
   "source": [
    "#### `log_message()`: Logs every major step in both the console and a persistent log file. This helps with tracking execution and debugging errors in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c309e-c583-45b0-af59-c8a127207c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_message(message):\n",
    "    \"\"\"Log messages to file and console with timestamp.\"\"\"\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_entry = f\"[{timestamp}] {message}\"\n",
    "    print(log_entry)\n",
    "    with open(\"analysis_log.txt\", 'a') as f:\n",
    "        f.write(log_entry + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b4cf5b-104e-463f-a896-446631823e76",
   "metadata": {},
   "source": [
    "### `generate_mock_data` Used if file download fails; creates respondent files with a simple answer pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a95841-0b70-4d30-8144-2628a1cfe865",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_mock_data(num_files=5):\n",
    "    for i in range(1, num_files + 1):\n",
    "        with open(file_path, 'w') as f:\n",
    "            for q in range(1, 101):\n",
    "                if q % 4 == opt % 4:\n",
    "                    f.write(f\"[x] Answer {q}.{opt}\\n\")40}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeaaef4-b3c7-411e-ae98-01523d1a8ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0114bd2b-92bb-4dfc-aacb-a3390f78be8f",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This integration script shows amazing software practice with:\n",
    "* Great modular design\n",
    "* Robust error handling\n",
    "* Detailed logging and comments and files\n",
    "* Type hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d0834-649c-4812-b953-f55dd1ee587e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
